---
title: "Training Uncertainty-Aware Classifiers with Conformalized Deep Learning"
collection: publications
permalink: /publication/2022-conf-learn
excerpt: "A flexible conformal inference method is developed to construct confidence intervals for the frequencies of queried objects in a very large data set, based on the information contained in a much smaller sketch of those data."
date: 2022-05-12
venue: 'pre-print'
paperurl: 'https://arxiv.org/abs/2205.05878'
citation: 'Einbinder, Romano, Sesia, and Zhou (2022). &quot;Training Uncertainty-Aware Classifiers with Conformalized Deep Learning.&quot; <i>arXiv</i>.'
---

**Abstract**

Deep neural networks are powerful tools to detect hidden patterns in data and leverage them to make predictions, but they are not designed to understand uncertainty and estimate reliable probabilities. In particular, they tend to be overconfident. We address this problem by developing a novel training algorithm that can lead to more dependable uncertainty estimates, without sacrificing predictive power. The idea is to mitigate overconfidence by minimizing a loss function, inspired by advances in conformal inference, that quantifies model uncertainty by carefully leveraging hold-out data. Experiments with synthetic and real data demonstrate this method leads to smaller conformal prediction sets with higher conditional coverage, after exact calibration with hold-out data, compared to state-of-the-art alternatives. 

[Download paper here](http://msesia.github.io/files/conformalized_learning.pdf)