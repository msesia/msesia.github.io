---
title: "Noise-Adaptive Conformal Classification with Marginal Coverage"
collection: publications
permalink: /publication/2025-marginal-label-noise
excerpt: ''
date: 2025-01-29
venue: 'pre-print'
---

**Abstract**

Conformal inference provides a rigorous statistical framework for uncertainty quantification in machine learning, enabling well-calibrated prediction sets with precise coverage guarantees for any classification model. However, its reliance on the idealized assumption of perfect data exchangeability limits its effectiveness in the presence of real-world complications, such as low-quality labels -- a widespread issue in modern large-scale data sets. This work tackles this open problem by introducing an adaptive conformal inference method capable of efficiently handling deviations from exchangeability caused by random label noise, leading to informative prediction sets with tight marginal coverage guarantees even in those challenging scenarios. We validate our method through extensive numerical experiments demonstrating its effectiveness on synthetic and real data sets, including CIFAR-10H and BigEarthNet. 


[Download paper here](https://arxiv.org/pdf/2501.18060.pdf)